---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi there! 

Welcome to the website of Hanyang Kong (å­”æ™—æ—¸). ğŸŒ  

I am honored to be pursuing my Ph.D. at the [Learning and Vision Lab @ NUS](http://www.lv-nus.org/), advised by [Prof. Xinchao Wang](https://sites.google.com/site/sitexinchaowang/) since August 2021. My academic journey in computer science previously led me to Xi'an Jiaotong University, where I completed my master's degree under the mentorship of [Prof. Qingyu Yang](https://gr.xjtu.edu.cn/web/yangqingyu/1). ğŸ“

My research is centered on AIGC (Artificial Intelligence-Generated Content) and LLM (Large Language Models), focusing on:
- ğŸ“Š **3D Generation and Estimation**: Striving to contribute to the evolution of digital modeling.
- ğŸ’¡ **Diffusion Models and LLM Applications**: Aiming to bridge advanced AI with real-world applications.

Thank you for your interest. Please feel free to explore the site to learn more about my research and academic endeavors. ğŸ”


# ğŸ”¥ News
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ Our paper *DreamDrone: Text-to-Image Diffusion Models are Zero-shot Perpetual View Generators* was accepted by ECCVâ€™24. 
- *2023.12*: &nbsp;ğŸ‰ğŸ‰ ğŸŒŸOur new work, *DreamDrone: Text-to-Image Diffusion Models are Zero-shot Perpetual View Generators*, is released! Check our [paper](https://arxiv.org/abs/2312.08746) and [code](https://github.com/HyoKong/DreamDrone.git)! Also, please feel free to try our online [huggingface demo](https://huggingface.co/spaces/imsuperkong/dreamdrone)!
- *2023.07*: &nbsp;ğŸ‰ğŸ‰ Our paper *Priority-centric human motion generation in discrete latent space* was accepted by ICCVâ€™23. 

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/dreamdrone.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[***DreamDrone: Text-to-Image Diffusion Models are Zero-shot Perpetual View Generators***](https://arxiv.org/abs/2312.08746.pdf) <img src='https://img.shields.io/github/stars/HyoKong/DreamDrone.svg?style=social&label=Star' alt="sym" height="100%">

**Hanyang Kong**, Dongze Lian, Michael Bi Mi, Xinchao Wang

[**Project page**](https://hyokong.github.io/dreamdrone-page/), [**Huggingface demo**](https://huggingface.co/spaces/imsuperkong/dreamdrone), [**Code**](https://github.com/HyoKong/DreamDrone.git), [**Arxiv**](https://arxiv.org/abs/2312.08746) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- **Zero-shot, Training-Free Scene Creation:** Generates perceptual scenes directly from text, without specific training for each scene.
- **Click-Guided Dreamscapes Navigation:** Allows drone flight control through point selection, offering a visually immersive experience.
- **Resource-Efficient Scene Generation:** Omits the need for a 3D point cloud, enabling faster scene creation with lower computational demand.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/t2m.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[***Priority-Centric Human Motion Generation in Discrete Latent Space***](https://arxiv.org/pdf/2308.14480.pdf)

**Hanyang Kong**, Kehong Gong, Dongze Lian, Michael Bi Mi, Xinchao Wang

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Text-to-motion generation in descrete latent space. 
- Priority-centric diffusion scheme for the discrete diffusion model.
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<!-- # ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- - *2015-2019(B.Eng.)*:  -->

# ğŸ“– Educations
- *2021.08 - present*: Ph.D. candidate in College of Design and Engineering, National University of Singapore.
- *2017.08 - 2020.06*: M.Eng. in Faculty of Electronic and Information Engineering, Xi'an Jiaotong University. 
- *2013.08 - 2017.06*: B.Eng. in Faculty of Electrical Engineering and Automation, Hefei University of Technology. 


<!-- # ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
